<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8" />

    

    

    <title>robots.txt文件 | Hexo</title>
    <meta name="author" content="John Doe" />
    <meta name="keywords" content="" />
    <meta name="description" content="一、robots.txt文件Robots.txt文件是网站跟爬虫间的协议，对于专业SEO并不陌生，用简单直接的txt格式文本方式告诉对应的爬虫被允许的权限，也就是说robots.txt是搜索引擎中访问网站的时候要查看的第一个文件。当一个搜索蜘蛛访问一个站点时，它会首先检查该站点根目录下是否存在robots.txt，如果存在，搜索机器人就会按照该文件中的内容来确定访问的范围；如果该文件不存在，所有的搜索蜘蛛将能够访问网站上所有没有被口令保护的页面。如您的网站未设置robots协议，搜索引擎对网站视" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />

    
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/logo.jpg">
    

    <style type="text/css">
    @font-face {
        font-family: 'icomoon';
        src: url("/fonts/icomoon.eot?q628ml");
        src: url("/fonts/icomoon.eot?q628ml#iefix") format('embedded-opentype'),
             url("/fonts/icomoon.ttf?q628ml") format('truetype'),
             url("/fonts/icomoon.woff?q628ml") format('woff'),
             url("/fonts/icomoon.svg?q628ml#icomoon") format('svg');
        font-weight: normal;
        font-style: normal;
    }
    </style>
    
<link rel="stylesheet" href="/css/style.css">


    <!--[if lt IE 9]><style type="text/css">.nav-inner {top:0;}.author-meta {position:static;top:0;}.search-form {height:36px;}</style><script type="text/javascript" src="https://unpkg.com/html5shiv@3.7.3/dist/html5shiv.min.js"></script><![endif]-->
<meta name="generator" content="Hexo 6.3.0"></head>
<body>

    <main class="app">
        <header id="header" class="header clearfix">
    <div id="nav" class="nav">
    <div class="nav-mobile">
        <button id="open-panel" class="open-panel nav-mobile-item"><i class="icon-documents"></i></button>
        <h1 class="nav-mobile-title nav-mobile-item">Hexo</h1>
        <button id="open-menus" class="open-panel nav-mobile-item"><i class="icon-library"></i></button>
    </div>

    <nav id="nav-inner" class="nav-inner">
        
            <a class="nav-item" href="/">
                <span class="nav-text">首页</span>
            </a>
        
            <a class="nav-item" href="/categories/front-end">
                <span class="nav-text">前端</span>
            </a>
        
            <a class="nav-item" href="/categories/back-end">
                <span class="nav-text">后端</span>
            </a>
        
            <a class="nav-item" href="/tags">
                <span class="nav-text">标签</span>
            </a>
        
            <a class="nav-item" href="/archives">
                <span class="nav-text">归档</span>
            </a>
        
            <a class="nav-item" href="/atom.xml">
                <span class="nav-text">订阅</span>
            </a>
        
            <a class="nav-item" href="/about">
                <span class="nav-text">关于</span>
            </a>
        
    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="http://example.com"></form>

        
        
        
        

        
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81robots-txt%E6%96%87%E4%BB%B6"><span class="toc-number">1.</span> <span class="toc-text">一、robots.txt文件</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Robots-txt%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%99%E6%B3%95"><span class="toc-number">1.1.</span> <span class="toc-text">二、Robots.txt文件的写法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9C%A8%E7%BA%BF%E7%94%9F%E6%88%90Robots-txt-%E6%96%87%E4%BB%B6"><span class="toc-number">1.1.1.</span> <span class="toc-text">三、在线生成Robots.txt 文件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Robots-txt%E5%9C%A8%E7%BA%BF%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">四、Robots.txt在线检测工具</span></a></li></ol></li></ol></li></ol></li></ol>
        
    </div>
</aside>

</header>

        <div id="content" class="content">
            <div id="wrapper" class="wrapper" style="max-width: 800px">
                <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            robots.txt文件
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="http://example.com/2023/07/05/robots-txt%E6%96%87%E4%BB%B6/index.html">
    
    <i class="icon-calendar vm"></i>
    
    <time class="vm" datetime="2023-07-05T08:14:30.000Z" itemprop="datePublished">2023-07-05</time>
</a>

            

        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="一、robots-txt文件"><a href="#一、robots-txt文件" class="headerlink" title="一、robots.txt文件"></a>一、robots.txt文件</h1><ol>
<li><p>Robots.txt文件是网站跟爬虫间的协议，对于专业SEO并不陌生，用简单直接的txt格式文本方式告诉对应的爬虫被允许的权限，也就是说robots.txt是搜索引擎中访问网站的时候要查看的第一个文件。当一个搜索蜘蛛访问一个站点时，它会首先检查该站点根目录下是否存在robots.txt，如果存在，搜索机器人就会按照该文件中的内容来确定访问的范围；如果该文件不存在，所有的搜索蜘蛛将能够访问网站上所有没有被口令保护的页面。</p>
</li>
<li><p>如您的网站未设置robots协议，搜索引擎对网站视频URL的收录将包含视频播放页URL，及页面中的视频文件、视频周边文本等信息，搜索对已收录的短视频资源将对用户呈现为视频极速体验页。此外，综艺影视类长视频，搜索引擎仅收录页面URL。</p>
</li>
</ol>
<hr>
<p><strong>User-agent:</strong><br>该项的值用于描述搜索引擎robot的名字，在”robots.txt”文件中，如果有多条User-agent记录说明有多个robot会受到该协议的限制，对该文件来说，至少要有一条User-agent记录。如果该项的值设为*，则该协议对任何机器人均有效，在”robots.txt”文件中，”User-agent:*”这样的记录只能有一条。<br><strong>Disallow:</strong><br>该项的值用于描述不希望被访问到的一个URL，这个URL可以是一条完整的路径，也可以是部分的，任何以Disallow开头的URL均不会被robot访问到。例如”Disallow:&#x2F;help”对&#x2F;help.html 和&#x2F;help&#x2F;index.html都不允许搜索引擎访问，而”Disallow:&#x2F;help&#x2F;”则允许robot访问&#x2F;help.html，而不能访问&#x2F;help&#x2F;index.html。任何一条Disallow记录为空，说明该网站的所有部分都允许被访问，在”&#x2F;robots.txt”文件中，至少要有一条Disallow记录。如果”&#x2F;robots.txt”是一个空文件，则对于所有的搜索引擎robot，该网站都是开放的。<br><strong>Allow:</strong><br>该项的值用于描述希望被访问的一组URL，与Disallow项相似，这个值可以是一条完整的路径，也可以是路径的前缀，以Allow项的值开头的URL是允许robot访问的。例如”Allow:&#x2F;hibaidu”允许robot访问&#x2F;hibaidu.htm、&#x2F;hibaiducom.html、&#x2F;hibaidu&#x2F;com.html。一个网站的所有URL默认是Allow的，所以Allow通常与Disallow搭配使用，实现允许访问一部分网页同时禁止访问其它所有URL的功能。<br>需要特别注意的是Disallow与Allow行的顺序是有意义的，robot会根据第一个匹配成功的Allow或Disallow行确定是否访问某个URL。</p>
<p><em>使用”</em>”和”$”：*<br>robots支持使用通配符”<em>”和”$”来模糊匹配url：<br>“$” 匹配行结束符。<br>“</em>” 匹配0或多个任意字符。</p>
<h2 id="二、Robots-txt文件的写法"><a href="#二、Robots-txt文件的写法" class="headerlink" title="二、Robots.txt文件的写法"></a>二、Robots.txt文件的写法</h2><ul>
<li>User-agent: *   (头部标准)</li>
<li>Allow: &#x2F;        （允许全部搜索引擎捉取）</li>
<li>User-agent: Googlebot (谷歌蜘蛛)</li>
<li>Disallow:       （默认捉取）</li>
<li>User-agent: Baiduspider (百度蜘蛛)</li>
<li>Disallow: &#x2F;      （禁止捉取）</li>
<li>Sitemap: <a target="_blank" rel="noopener" href="https://www.l.cn/sitemap.xml">https://www.l.cn/sitemap.xml</a>  （站点地图）</li>
</ul>
<h3 id="三、在线生成Robots-txt-文件"><a href="#三、在线生成Robots-txt-文件" class="headerlink" title="三、在线生成Robots.txt 文件"></a>三、在线生成Robots.txt 文件</h3><p>站长工具Robots.txt生成：<a target="_blank" rel="noopener" href="http://tool.chinaz.com/robots/">http://tool.chinaz.com/robots/</a><br>便民查询网Robots.txt生成器：<a target="_blank" rel="noopener" href="https://robots.51240.com/">https://robots.51240.com/</a><br>Tool在线工具：<a target="_blank" rel="noopener" href="https://www.qtool.net/robots">https://www.qtool.net/robots</a></p>
<h4 id="四、Robots-txt在线检测工具"><a href="#四、Robots-txt在线检测工具" class="headerlink" title="四、Robots.txt在线检测工具"></a>四、Robots.txt在线检测工具</h4><p>当写好robots.txt文件就需要检测是否有写，下面提供几款在线工具帮助大家检测robots是否有写错。</p>
<p>爱站Robots.txt检测工具：<a target="_blank" rel="noopener" href="https://tools.aizhan.com/robots/">https://tools.aizhan.com/robots/</a></p>
<p>站长工具Robots.txt检测：<a target="_blank" rel="noopener" href="http://s.tool.chinaz.com/robots/">http://s.tool.chinaz.com/robots/</a></p>

        
    </section>
</article>



<div class="comments">
    <div id="comments"></div>
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>
    new Gitalk({
        clientID: "7fbe80427f54741e289f",
        clientSecret: "f34ed5fd92e54c9000bd37ba951948cb939deff5",
        repo: "sanonz.github.io",
        owner: "sanonz",
        admin: ["sanonz"],
        id: "32b50396b1dff86f5049336cf8e30b08",
        distractionFreeMode: true,
        title: "robots.txt文件",
        body: "http://example.com/2023/07/05/robots-txt%E6%96%87%E4%BB%B6/",
        labels: []
    }).render('comments');
    </script>
</div>



            </div>
        </div>

        
            
            <a id="pagenext" href="/2023/07/01/gopher%E5%8D%8F%E8%AE%AE/" class="article-next" title="gopher协议"><i class="icon-arrow-right"></i></a>
            
            
        

        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>

    
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?e4027971a230b210f4671f485b33846a";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
</footer>

    </main>

    <script type="text/javascript" src="https://unpkg.com/jquery@1.9.1/jquery.min.js"></script>
    <script type="text/javascript">
    $(function() {
        var nodes = {
            nav: $('#nav'),
            aside: $('#aside'),
            asideInner: $('#aside-inner'),
            navInner: $('#nav-inner')
        };

        var doing = false;
        nodes.asideInner.on('webkitAnimationEnd mozAnimationEnd oAnimationEnd oanimationend animationend', function() {
            if (nodes.aside.hasClass('mobile-open')) {
                nodes.aside.removeClass('mobile-open');
            } else {
                nodes.aside.removeClass('mobile-close panel-show');
            }
            doing = false;
        });
        $('#open-panel, #aside-mask').on('click', function() {
            if (doing) {
                return;
            }

            if (nodes.aside.hasClass('panel-show')) {
                nodes.aside.addClass('mobile-close');
            } else {
                nodes.aside.addClass('mobile-open panel-show');
            }
        });
        $('#open-menus').on('click', function() {
            nodes.navInner.slideToggle('normal', slideDone);
        });

        if (window.innerWidth <= 960) {
            setTimeout(function() {
                nodes.navInner.slideUp('normal', slideDone);
            }, 3000);
        }

        function slideDone() {
            if (nodes.navInner.css('display') !== 'none') {
                nodes.navInner.css('display', '');
            }
        }

        $(window).on('resize', function() {
            if ($(this).width() > 960) {
                nodes.navInner.css('display', '');
            }
        });
    });
    </script>
    
        
<script src="/js/scrollspy.min.js"></script>

        <script type="text/javascript">
        $(document.body).scrollspy({target: '#aside-inner'});

        $(window).on('resize', function() {
            var hw = $('#header').width();
            var ww = $('#wrapper').width();
            var space = ($(this).width() - hw - ww) / 2 / 2;

            var pageprev = $('#pageprev');
            var pagenext = $('#pagenext');
            var avg = (pageprev.width() + pagenext.width()) / 2

            if(space > avg) {
                var len = space - avg / 2;
                var styles = {position: 'fixed', top: '50%', marginTop: - (pageprev.width() + pagenext.width()) / 4}
                pageprev.css($.extend({left: hw + len}, styles));
                pagenext.css($.extend({right: len}, styles));
            } else {
                pageprev.removeAttr('style');
                pagenext.removeAttr('style');
            }
        }).trigger('resize');
        </script>
    

</body>
</html>
